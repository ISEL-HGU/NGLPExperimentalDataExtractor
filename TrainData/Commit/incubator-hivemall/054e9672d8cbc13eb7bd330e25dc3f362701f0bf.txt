import hivemall.UDFWithOptions;
import java.util.Objects;
import org.apache.commons.cli.CommandLine;
import org.apache.commons.cli.Options;
import org.apache.lucene.analysis.ja.tokenattributes.PartOfSpeechAttribute;
import com.clearspring.analytics.util.Preconditions;

public final class KuromojiUDF extends UDFWithOptions {
    private boolean _returnPos;
    private transient Object[] _result;
    protected Options getOptions() {
        Options opts = new Options();
        opts.addOption("mode", true,
            "The tokenization mode. One of ['normal', 'search', 'extended', 'default' (normal)]");
        opts.addOption("pos", false, "Return part-of-speech information");
        return opts;
    }

    @Override
    protected CommandLine processOptions(String optionValue) throws UDFArgumentException {
        CommandLine cl = parseOptions(optionValue);
        if (cl.hasOption("mode")) {
            String modeStr = cl.getOptionValue("mode");
            this._mode = tokenizationMode(modeStr);
        }
        this._returnPos = cl.hasOption("pos");
        return cl;
    }

    @Override
            showHelp("Invalid number of arguments for `tokenize_ja`: "  arglen);
        this._mode = Mode.NORMAL;
        if (arglen >= 2) {
            String arg1 = HiveUtils.getConstString(arguments[1]);
            if (arg1 != null) {
                if (arg1.startsWith("-")) {
                    processOptions(arg1);
                } else {
                    this._mode = tokenizationMode(arg1);
                }
            }
        }
        if (_returnPos) {
            this._result = new Object[2];
            ArrayList<String> fieldNames = new ArrayList<String>();
            ArrayList<ObjectInspector> fieldOIs = new ArrayList<ObjectInspector>();
            fieldNames.add("tokens");
            fieldOIs.add(ObjectInspectorFactory.getStandardListObjectInspector(
                PrimitiveObjectInspectorFactory.writableStringObjectInspector));
            fieldNames.add("pos");
            fieldOIs.add(ObjectInspectorFactory.getStandardListObjectInspector(
                PrimitiveObjectInspectorFactory.writableStringObjectInspector));
            return ObjectInspectorFactory.getStandardStructObjectInspector(fieldNames, fieldOIs);
        } else {
            return ObjectInspectorFactory.getStandardListObjectInspector(
                PrimitiveObjectInspectorFactory.writableStringObjectInspector);
        }
    public Object evaluate(DeferredObject[] arguments) throws HiveException {
        if (_returnPos) {
            return parseLine(_analyzer, line, _result);
        } else {
            return parseLine(_analyzer, line);
        }
    }

    @Nonnull
    private static Object[] parseLine(@Nonnull JapaneseAnalyzer analyzer, @Nonnull String line,
            @Nonnull Object[] result) throws HiveException {
        Objects.requireNonNull(result);
        Preconditions.checkArgument(result.length == 2);

        final List<Text> tokens = new ArrayList<Text>(32);
        final List<Text> pos = new ArrayList<Text>(32);
            stream = analyzer.tokenStream("", line);
                analyzeTokens(stream, tokens, pos);
            IOUtils.closeQuietly(analyzer);
        result[0] = tokens;
        result[1] = pos;
        return result;
    }

    @Nonnull
    private static List<Text> parseLine(@Nonnull JapaneseAnalyzer analyzer, @Nonnull String line)
            throws HiveException {
        final List<Text> tokens = new ArrayList<Text>(32);
        TokenStream stream = null;
        try {
            stream = analyzer.tokenStream("", line);
            if (stream != null) {
                analyzeTokens(stream, tokens);
            }
        } catch (IOException e) {
            IOUtils.closeQuietly(analyzer);
            throw new HiveException(e);
        } finally {
            IOUtils.closeQuietly(stream);
        }
        return tokens;
    private static Mode tokenizationMode(@Nonnull final String arg) throws UDFArgumentException {
    private static void analyzeTokens(@Nonnull final TokenStream stream,
            @Nonnull final List<Text> tokens) throws IOException {
            tokens.add(new Text(term));
        }
    }

    private static void analyzeTokens(@Nonnull final TokenStream stream,
            @Nonnull final List<Text> tokenResult, @Nonnull final List<Text> posResult)
            throws IOException {
        // instantiate an attribute placeholder once
        CharTermAttribute termAttr = stream.getAttribute(CharTermAttribute.class);
        PartOfSpeechAttribute posAttr = stream.addAttribute(PartOfSpeechAttribute.class);
        stream.reset();

        while (stream.incrementToken()) {
            String term = termAttr.toString();
            tokenResult.add(new Text(term));
            String pos = posAttr.getPartOfSpeech();
            posResult.add(new Text(pos));
